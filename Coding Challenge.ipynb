{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Or limit to a higher number (e.g., 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigquery_magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What We Review\n",
    "Your application will be reviewed by our engineers. The aspects of your code we will judge include:\n",
    "\n",
    "- ability to get the technical environment set up\n",
    "- sql coding knowledge\n",
    "- data cleaning and abstraction\n",
    "- understanding of time-dependent data\n",
    "- machine learning knowledge and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Will it snow tomorrow?\" - The time traveler asked\n",
    "The following dataset contains climate information from over 9000 stations accross the world. The overall goal of these subtasks will be to predict whether it will snow tomorrow 20 years ago. So if today is 1 April 2025 then the weather we want to forecast is for the 2 April 2005. You are supposed to solve the tasks using Big Query, which can be used in the Jupyter Notebook like it is shown in the following cell. For further information and how to use BigQuery in Jupyter Notebook refer to the Google Docs. \n",
    "\n",
    "The goal of this test is to test your coding knowledge in Python, BigQuery and Pandas as well as your understanding of Data Science. If you get stuck in the first part, you can use the replacement data provided in the second part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a4703d6bc74b9db21ae52a853526ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098a8d68fa8c4e79acc76b592e90a47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>num_mean_sealevel_pressure_samples</th>\n",
       "      <th>mean_station_pressure</th>\n",
       "      <th>num_mean_station_pressure_samples</th>\n",
       "      <th>mean_visibility</th>\n",
       "      <th>num_mean_visibility_samples</th>\n",
       "      <th>mean_wind_speed</th>\n",
       "      <th>num_mean_wind_speed_samples</th>\n",
       "      <th>max_sustained_wind_speed</th>\n",
       "      <th>max_gust_wind_speed</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>max_temperature_explicit</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.700012</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1037.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.900002</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37770</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>994.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>43.900002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38560</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>36.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>997.799988</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>46.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1028.099976</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30910</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>983.200012</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>53.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>46.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>17.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>48.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>1019.299988</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>36.900002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39530</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1001.099976</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>4</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33790</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>46.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.099976</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38940</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>50.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.400024</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.900002</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>58.799999</td>\n",
       "      <td>5</td>\n",
       "      <td>48.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>1008.900024</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>996.299988</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>32.700001</td>\n",
       "      <td>5</td>\n",
       "      <td>36.900002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34970</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>53.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1027.199951</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.900002</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38040</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>47.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1007.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32620</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>5</td>\n",
       "      <td>34.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1006.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30750</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>987.299988</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39800</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.099998</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.299988</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0            39800        99999  1929     11   13  41.299999   \n",
       "1            33110        99999  1929     12   16  45.500000   \n",
       "2            37770        99999  1929     12    8  48.000000   \n",
       "3            38560        99999  1929     11   13  44.500000   \n",
       "4            33110        99999  1929     12   15  46.700001   \n",
       "5            30910        99999  1929     10    6  50.000000   \n",
       "6            33110        99999  1929     10    1  53.299999   \n",
       "7            39730        99999  1929     11    4  54.000000   \n",
       "8            38110        99999  1929     11   18  43.500000   \n",
       "9            39530        99999  1929     10   23  54.000000   \n",
       "10           33790        99999  1929     10   21  46.799999   \n",
       "11           38940        99999  1929     10   19  50.200001   \n",
       "12           34970        99999  1929      8    5  58.799999   \n",
       "13           38040        99999  1929     11   19  54.000000   \n",
       "14           34970        99999  1929     10   13  53.200001   \n",
       "15           38040        99999  1929     12   27  47.200001   \n",
       "16           32620        99999  1929     12   31  38.200001   \n",
       "17           30750        99999  1930     10    6  46.500000   \n",
       "18           39800        99999  1930      7   27  57.500000   \n",
       "19           39730        99999  1930      2   14  43.500000   \n",
       "\n",
       "    num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                       4       37.000000                           4   \n",
       "1                       4       34.500000                           4   \n",
       "2                       4       42.000000                           4   \n",
       "3                       4       36.200001                           4   \n",
       "4                       4       42.500000                           4   \n",
       "5                       4             NaN                        <NA>   \n",
       "6                       4       46.299999                           4   \n",
       "7                       4       48.700001                           4   \n",
       "8                       4       39.500000                           4   \n",
       "9                       4       50.000000                           4   \n",
       "10                      4       42.000000                           4   \n",
       "11                      4       44.000000                           4   \n",
       "12                      5       48.799999                           4   \n",
       "13                      5       53.000000                           4   \n",
       "14                      5       48.500000                           4   \n",
       "15                      5       45.500000                           4   \n",
       "16                      5       34.299999                           4   \n",
       "17                      4       45.500000                           4   \n",
       "18                      4       54.000000                           4   \n",
       "19                      4       38.299999                           4   \n",
       "\n",
       "    mean_sealevel_pressure  num_mean_sealevel_pressure_samples  \\\n",
       "0               996.700012                                   4   \n",
       "1              1037.000000                                   4   \n",
       "2               994.500000                                   4   \n",
       "3               997.799988                                   4   \n",
       "4              1028.099976                                   4   \n",
       "5               983.200012                                   4   \n",
       "6              1010.000000                                   4   \n",
       "7              1019.299988                                   4   \n",
       "8              1016.299988                                   4   \n",
       "9              1001.099976                                   4   \n",
       "10             1007.099976                                   4   \n",
       "11             1008.400024                                   4   \n",
       "12             1008.900024                                   5   \n",
       "13              996.299988                                   5   \n",
       "14             1027.199951                                   5   \n",
       "15             1007.500000                                   5   \n",
       "16             1006.500000                                   5   \n",
       "17              987.299988                                   4   \n",
       "18             1005.000000                                   4   \n",
       "19             1016.299988                                   4   \n",
       "\n",
       "    mean_station_pressure  num_mean_station_pressure_samples  mean_visibility  \\\n",
       "0                     NaN                               <NA>         7.800000   \n",
       "1                     NaN                               <NA>        12.400000   \n",
       "2                     NaN                               <NA>         2.200000   \n",
       "3                     NaN                               <NA>        10.900000   \n",
       "4                     NaN                               <NA>         9.900000   \n",
       "5                     NaN                               <NA>         2.200000   \n",
       "6                     NaN                               <NA>        17.700001   \n",
       "7                     NaN                               <NA>         6.800000   \n",
       "8                     NaN                               <NA>         5.300000   \n",
       "9                     NaN                               <NA>         7.900000   \n",
       "10                    NaN                               <NA>         7.500000   \n",
       "11                    NaN                               <NA>        20.200001   \n",
       "12                    NaN                               <NA>         4.700000   \n",
       "13                    NaN                               <NA>         2.000000   \n",
       "14                    NaN                               <NA>         3.200000   \n",
       "15                    NaN                               <NA>         7.500000   \n",
       "16                    NaN                               <NA>         5.200000   \n",
       "17                    NaN                               <NA>        12.400000   \n",
       "18                    NaN                               <NA>         9.300000   \n",
       "19                    NaN                               <NA>         5.300000   \n",
       "\n",
       "    num_mean_visibility_samples  mean_wind_speed  num_mean_wind_speed_samples  \\\n",
       "0                             4        17.000000                            4   \n",
       "1                             4         8.900000                            4   \n",
       "2                             4        28.900000                            4   \n",
       "3                             4         9.000000                            4   \n",
       "4                             4        17.000000                            4   \n",
       "5                             4        14.500000                            4   \n",
       "6                             4        13.000000                            4   \n",
       "7                             4        19.700001                            4   \n",
       "8                             4        16.500000                            4   \n",
       "9                             4        17.500000                            4   \n",
       "10                            4         4.000000                            4   \n",
       "11                            4         5.400000                            4   \n",
       "12                            5         7.400000                            5   \n",
       "13                            5        32.700001                            5   \n",
       "14                            5         4.600000                            5   \n",
       "15                            5        20.400000                            5   \n",
       "16                            5         8.200000                            5   \n",
       "17                            4         9.000000                            4   \n",
       "18                            4         7.200000                            4   \n",
       "19                            4        11.000000                            4   \n",
       "\n",
       "    max_sustained_wind_speed  max_gust_wind_speed  max_temperature  \\\n",
       "0                  23.900000                  NaN        39.000000   \n",
       "1                   8.900000                  NaN        39.900002   \n",
       "2                  43.900002                  NaN        42.099998   \n",
       "3                  13.000000                  NaN        41.000000   \n",
       "4                  23.900000                  NaN        46.000000   \n",
       "5                  23.900000                  NaN        45.000000   \n",
       "6                  23.900000                  NaN        48.900002   \n",
       "7                  23.900000                  NaN        50.000000   \n",
       "8                  36.900002                  NaN        37.000000   \n",
       "9                  29.900000                  NaN        48.900002   \n",
       "10                  8.900000                  NaN        39.000000   \n",
       "11                  8.900000                  NaN        46.900002   \n",
       "12                  8.900000                  NaN        54.000000   \n",
       "13                 36.900002                  NaN        48.000000   \n",
       "14                  8.900000                  NaN        48.900002   \n",
       "15                 23.900000                  NaN        43.000000   \n",
       "16                  8.900000                  NaN        36.000000   \n",
       "17                 13.000000                  NaN        42.099998   \n",
       "18                 13.000000                  NaN        53.099998   \n",
       "19                 13.000000                  NaN        37.000000   \n",
       "\n",
       "    max_temperature_explicit  min_temperature  min_temperature_explicit  \\\n",
       "0                      False              NaN                      <NA>   \n",
       "1                      False              NaN                      <NA>   \n",
       "2                      False              NaN                      <NA>   \n",
       "3                      False              NaN                      <NA>   \n",
       "4                       True              NaN                      <NA>   \n",
       "5                       True              NaN                      <NA>   \n",
       "6                      False              NaN                      <NA>   \n",
       "7                      False              NaN                      <NA>   \n",
       "8                      False              NaN                      <NA>   \n",
       "9                      False              NaN                      <NA>   \n",
       "10                     False              NaN                      <NA>   \n",
       "11                     False              NaN                      <NA>   \n",
       "12                     False              NaN                      <NA>   \n",
       "13                     False              NaN                      <NA>   \n",
       "14                     False              NaN                      <NA>   \n",
       "15                      True              NaN                      <NA>   \n",
       "16                     False              NaN                      <NA>   \n",
       "17                     False              NaN                      <NA>   \n",
       "18                     False              NaN                      <NA>   \n",
       "19                     False              NaN                      <NA>   \n",
       "\n",
       "    total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                   NaN         NaN  False  False  False  False    False   \n",
       "1                  0.00         NaN  False  False  False  False    False   \n",
       "2                   NaN         NaN  False  False  False  False    False   \n",
       "3                   NaN         NaN  False  False  False  False    False   \n",
       "4                  0.00         NaN  False  False  False  False    False   \n",
       "5                   NaN         NaN  False  False  False  False    False   \n",
       "6                   NaN         NaN  False  False  False  False    False   \n",
       "7                   NaN         NaN  False  False  False  False    False   \n",
       "8                   NaN         NaN  False  False  False  False    False   \n",
       "9                   NaN         NaN  False  False  False  False    False   \n",
       "10                 0.00         NaN  False  False  False  False    False   \n",
       "11                  NaN         NaN  False  False  False  False    False   \n",
       "12                 0.02         NaN  False  False  False  False    False   \n",
       "13                 0.47         NaN  False  False  False  False    False   \n",
       "14                 0.00         NaN  False  False  False  False    False   \n",
       "15                 0.12         NaN  False  False  False  False    False   \n",
       "16                 0.00         NaN  False  False  False  False    False   \n",
       "17                  NaN         NaN  False  False  False  False    False   \n",
       "18                 0.00         NaN  False  False  False  False    False   \n",
       "19                  NaN         NaN  False  False  False  False    False   \n",
       "\n",
       "    tornado  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8     False  \n",
       "9     False  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16    False  \n",
       "17    False  \n",
       "18    False  \n",
       "19    False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT\n",
    "*,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "LIMIT 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Task\n",
    "Change the date format to 'YYYY-MM-DD' and select the data from 2000 till 2005 for station numbers including and between 725300 and 726300 , and save it as a pandas dataframe. Note the maximum year available is 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfee05d56ba4a84a35c96028fe43877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54405e8ac16d40d6bf41bd175b0276f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df_weather_filtered\n",
    "SELECT\n",
    "  *,\n",
    "  FORMAT_DATE('%Y-%m-%d', DATE(year, month, day)) AS date\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "  year BETWEEN 2000 AND 2005\n",
    "  AND station_number BETWEEN 725300 AND 726300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task \n",
    "From here you want to work with the data from all stations 725300 to 725330 that have information from 2000 till 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>num_mean_sealevel_pressure_samples</th>\n",
       "      <th>mean_station_pressure</th>\n",
       "      <th>num_mean_station_pressure_samples</th>\n",
       "      <th>mean_visibility</th>\n",
       "      <th>num_mean_visibility_samples</th>\n",
       "      <th>mean_wind_speed</th>\n",
       "      <th>num_mean_wind_speed_samples</th>\n",
       "      <th>max_sustained_wind_speed</th>\n",
       "      <th>max_gust_wind_speed</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>max_temperature_explicit</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>725835</td>\n",
       "      <td>99999</td>\n",
       "      <td>2000</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>35.599998</td>\n",
       "      <td>4</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>32.5</td>\n",
       "      <td>4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725826</td>\n",
       "      <td>99999</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>44.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>39.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-06-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725494</td>\n",
       "      <td>99999</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>49.099998</td>\n",
       "      <td>4</td>\n",
       "      <td>30.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>48.200001</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725868</td>\n",
       "      <td>99999</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725868</td>\n",
       "      <td>99999</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.400002</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2000-08-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0          725835        99999  2000     11    7  35.599998   \n",
       "1          725826        99999  2000      6    9  44.200001   \n",
       "2          725494        99999  2000      4   11  49.099998   \n",
       "3          725868        99999  2000      1    1  20.700001   \n",
       "4          725868        99999  2000      8   30  59.500000   \n",
       "\n",
       "   num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                      4       20.799999                           4   \n",
       "1                      4       39.200001                           4   \n",
       "2                      4       30.200001                           4   \n",
       "3                      4       15.300000                           4   \n",
       "4                      4       55.000000                           4   \n",
       "\n",
       "   mean_sealevel_pressure  num_mean_sealevel_pressure_samples  \\\n",
       "0                     NaN                                <NA>   \n",
       "1                     NaN                                <NA>   \n",
       "2                     NaN                                <NA>   \n",
       "3                     NaN                                <NA>   \n",
       "4                     NaN                                <NA>   \n",
       "\n",
       "   mean_station_pressure  num_mean_station_pressure_samples  mean_visibility  \\\n",
       "0                    NaN                               <NA>             32.5   \n",
       "1                    NaN                               <NA>             25.0   \n",
       "2                    NaN                               <NA>             10.0   \n",
       "3                    NaN                               <NA>             17.5   \n",
       "4                    NaN                               <NA>              4.3   \n",
       "\n",
       "   num_mean_visibility_samples  mean_wind_speed  num_mean_wind_speed_samples  \\\n",
       "0                            4              7.5                            4   \n",
       "1                            4              4.5                            4   \n",
       "2                            4             10.0                            4   \n",
       "3                            4              2.5                            4   \n",
       "4                            4              1.5                            4   \n",
       "\n",
       "   max_sustained_wind_speed  max_gust_wind_speed  max_temperature  \\\n",
       "0                       9.9                  NaN        28.400000   \n",
       "1                       8.0                  NaN        39.000000   \n",
       "2                      14.0                 16.9        48.200001   \n",
       "3                       9.9                  NaN         8.100000   \n",
       "4                       6.0                  NaN        55.400002   \n",
       "\n",
       "   max_temperature_explicit  min_temperature  min_temperature_explicit  \\\n",
       "0                      True              NaN                      <NA>   \n",
       "1                     False              NaN                      <NA>   \n",
       "2                      True              NaN                      <NA>   \n",
       "3                     False              NaN                      <NA>   \n",
       "4                      True              NaN                      <NA>   \n",
       "\n",
       "   total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                  NaN         NaN  False  False  False  False    False   \n",
       "1                  NaN         NaN  False  False  False  False    False   \n",
       "2                 0.00         NaN  False  False  False  False    False   \n",
       "3                 0.00         3.9  False  False  False  False    False   \n",
       "4                 0.08         NaN  False  False  False  False    False   \n",
       "\n",
       "   tornado        date  \n",
       "0    False  2000-11-07  \n",
       "1    False  2000-06-09  \n",
       "2    False  2000-04-11  \n",
       "3    False  2000-01-01  \n",
       "4    False  2000-08-30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking which year received the most snowfall in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with the most snow: 2005 (13623 snowy days)\n"
     ]
    }
   ],
   "source": [
    "# %%bigquery\n",
    "\n",
    "# Extract the year from the formatted date column\n",
    "df_weather_filtered['year'] = pd.to_datetime(df_weather_filtered['date']).dt.year\n",
    "\n",
    "# Group by year and sum up the number of snowy days\n",
    "snow_by_year = df_weather_filtered[df_weather_filtered['snow'] == True].groupby('year').size()\n",
    "\n",
    "# Find the year with the maximum number of snow days\n",
    "year_with_most_snow = snow_by_year.idxmax()\n",
    "max_snow_days = snow_by_year.max()\n",
    "\n",
    "print(f\"Year with the most snow: {year_with_most_snow} ({max_snow_days} snowy days)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconfirming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67539224db77481bab883e27396285ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc11e47abb4461c8b9610827501777c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery snowiest_years\n",
    "WITH snow_days AS (\n",
    "  SELECT\n",
    "    year,\n",
    "    COUNTIF(snow = TRUE) AS n_snowy_days\n",
    "  FROM\n",
    "    `bigquery-public-data.samples.gsod`\n",
    "  WHERE\n",
    "    year BETWEEN 2000 AND 2005\n",
    "    AND station_number BETWEEN 725300 AND 726300\n",
    "  GROUP BY\n",
    "    year\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  year,\n",
    "  n_snowy_days\n",
    "FROM\n",
    "  snow_days\n",
    "WHERE\n",
    "  n_snowy_days = (\n",
    "    SELECT MAX(n_snowy_days) FROM snow_days\n",
    ")\n",
    "ORDER BY year;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowiest years with the most snowy days:\n",
      "   year  n_snowy_days\n",
      "0  2005         13623\n"
     ]
    }
   ],
   "source": [
    "print(\"Snowiest years with the most snowy days:\")\n",
    "print(snowiest_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fac32ccd704757a8d6616685812418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85696aa347304feeb150b1074cecd84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery snowiest_by_depth\n",
    "SELECT\n",
    "  year,\n",
    "  SUM(snow_depth) AS total_snow_depth_inches,\n",
    "  COUNT(snow_depth) AS days_with_snow_depth\n",
    "FROM\n",
    "  `bigquery-public-data.samples.gsod`\n",
    "WHERE\n",
    "  year BETWEEN 2000 AND 2005\n",
    "  AND station_number BETWEEN 725300 AND 726300\n",
    "  AND snow_depth IS NOT NULL\n",
    "GROUP BY\n",
    "  year\n",
    "ORDER BY\n",
    "  total_snow_depth_inches DESC\n",
    "LIMIT 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowiest year by total snow depth:\n",
      "   year  total_snow_depth_inches  days_with_snow_depth\n",
      "0  2001             13089.700075                  1849\n"
     ]
    }
   ],
   "source": [
    "print(\"Snowiest year by total snow depth:\")\n",
    "print(snowiest_by_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an additional field that indicates the daily change in snow depth measured at every station. And identify the station and day for which the snow depth increased the most.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25970c78610404395153991a3f1280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11ffe5419c945119074485724dce91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df_weather_filtered\n",
    "SELECT\n",
    "  station_number,\n",
    "  DATE(year, month, day) AS date,\n",
    "  snow_depth\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "WHERE year BETWEEN 2000 AND 2005\n",
    "  AND station_number BETWEEN 725300 AND 726300\n",
    "  AND snow_depth IS NOT NULL              -- no NULLs\n",
    "  AND snow_depth NOT IN (999.9, 9999.9)   -- no sentinel junk\n",
    "ORDER BY station_number, date             -- pre-sorted in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Biggest one-day snow-depth increase\n",
      "  Station : 725780\n",
      "  Date    : 2004-01-20\n",
      "  Depth  : 88.9 inches\n"
     ]
    }
   ],
   "source": [
    "df_weather_filtered['snow_depth_change'] = (\n",
    "    df_weather_filtered\n",
    "      .groupby('station_number')['snow_depth']\n",
    "      .diff()\n",
    ")\n",
    "\n",
    "max_idx = df_weather_filtered['snow_depth_change'].idxmax()\n",
    "max_jump = df_weather_filtered.loc[max_idx]\n",
    "\n",
    "print(\" Biggest one-day snow-depth increase\")\n",
    "print(f\"  Station : {int(max_jump.station_number)}\")\n",
    "print(f\"  Date    : {max_jump['date']}\")\n",
    "print(f\"  Depth  : {max_jump.snow_depth_change:.1f} inches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notes:\n",
    "\n",
    "Negative values = melting or measurement noise.\n",
    "\n",
    "NaNs are handled naturally by diff() (e.g., first entry per group)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today:        2025-06-21\n",
      "Test date:    2005-06-22\n",
      "Train set:    (400838, 33)\n",
      "Eval set:     (6217, 33)\n",
      "Test set:     (206, 33)\n",
      "Test date rows: <DatetimeArray>\n",
      "['2005-06-22 00:00:00']\n",
      "Length: 1, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Copy to avoid modifying original\n",
    "df = df_weather_filtered.copy()\n",
    "\n",
    "# Ensure datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Define today's date\n",
    "today = dt.datetime.today()\n",
    "\n",
    "# Calculate test date: 20 years ago + 1 day\n",
    "test_date = today - relativedelta(years=20) + dt.timedelta(days=1)\n",
    "test_date = test_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Define evaluation set: 30 days before test date\n",
    "eval_start = test_date - dt.timedelta(days=30)\n",
    "\n",
    "# Split the data\n",
    "df_test = df[df['date'] == test_date]\n",
    "df_eval = df[(df['date'] >= eval_start) & (df['date'] < test_date)]\n",
    "df_train = df[df['date'] < eval_start]\n",
    "\n",
    "# Debug/inspect\n",
    "print(f\"Today:        {today.date()}\")\n",
    "print(f\"Test date:    {test_date.date()}\")\n",
    "print(f\"Train set:    {df_train.shape}\")\n",
    "print(f\"Eval set:     {df_eval.shape}\")\n",
    "print(f\"Test set:     {df_test.shape}\")\n",
    "print(f\"Test date rows: {df_test['date'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass it through Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This pipeline structure is created to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureDropper fit complete. 34 total columns.\n",
      "Dropping 14 always dropped columns: ['year', 'day', 'wban_number', 'num_mean_temp_samples', 'num_mean_sealevel_pressure_samples', 'num_mean_wind_speed_samples', 'max_gust_wind_speed', 'max_sustained_wind_speed', 'mean_wind_speed', 'hail', 'tornado', 'thunder', 'fog', 'rain']\n",
      "Dropping 6 columns due to high missing values: ['mean_station_pressure', 'num_mean_station_pressure_samples', 'min_temperature', 'min_temperature_explicit', 'snow_depth', 'snow_depth_change']\n",
      "Dropping 4 columns due to high correlation: ['num_mean_dew_point_samples', 'num_mean_visibility_samples', 'max_gust_wind_speed', 'max_temperature']\n",
      "Dropping 10 columns from training: ['min_temperature_explicit', 'max_gust_wind_speed', 'min_temperature', 'snow_depth_change', 'num_mean_dew_point_samples', 'num_mean_station_pressure_samples', 'num_mean_visibility_samples', 'max_temperature', 'snow_depth', 'mean_station_pressure']\n"
     ]
    }
   ],
   "source": [
    "from pipeline.transformers.median_imputer import MedianImputer\n",
    "from pipeline.transformers.cyclical_encoder import MonthCyclicalEncoder\n",
    "from pipeline.transformers.outlier import IQRGroupOutlierRemover\n",
    "from pipeline.pipeline_runner import PipelineRunner\n",
    "from pipeline.transformers.feature_dropper import FeatureDropper\n",
    "from pipeline.transformers.binary_flag_imputer import BinaryFlagImputerEncoder\n",
    "from pipeline.transformers.log_transform import LogTransformer\n",
    "from pipeline.transformers.mean_imputer import MeanImputer\n",
    "from pipeline.transformers.knn_imputer import KNNImputerWrapper\n",
    "from pipeline.transformers.mode_imputer import ModeImputer\n",
    "from pipeline.transformers.lag_feature_generator import LagFeatureGenerator\n",
    "from pipeline.transformers.target_lag import TargetLagTransformer\n",
    "\n",
    "\n",
    "def separate_X_y(df, target_col='snow_tomorrow', drop_cols=['date']):\n",
    "    # Check that target exists\n",
    "    assert target_col in df.columns, f\"Target column '{target_col}' not found in DataFrame.\"\n",
    "    \n",
    "    # Drop target and any specified columns from features\n",
    "    X = df.drop(columns=[target_col] + drop_cols, errors='ignore')\n",
    "    y = df[target_col].astype(int)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Define columns\n",
    "median_cols = ['mean_temp', 'mean_dew_point', 'mean_sealevel_pressure', 'max_temperature']\n",
    "numeric_cols = df_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Columns to always drop from all splits\n",
    "always_drop_cols = [\n",
    "    'year', \n",
    "    # 'month', \n",
    "    'day', 'wban_number',\n",
    "    'num_mean_temp_samples', 'num_mean_sealevel_pressure_samples',\n",
    "    'num_mean_wind_speed_samples', 'max_gust_wind_speed',\n",
    "    'max_sustained_wind_speed', 'mean_wind_speed', \n",
    "    'hail', 'tornado', 'thunder', 'fog', 'rain',\n",
    "\n",
    "    # 'month_sin'\n",
    "]\n",
    "\n",
    "binary_flags = ['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado','max_temperature_explicit']\n",
    "\n",
    "\n",
    "cols_to_log_transform = [\n",
    "    # 'mean_wind_speed',\n",
    "    # 'max_sustained_wind_speed',\n",
    "    'total_precipitation'\n",
    "]\n",
    "\n",
    "cols_to_knn_impute = ['total_precipitation', 'mean_visibility']\n",
    "\n",
    "# Build pipeline\n",
    "pipeline_steps = [\n",
    "    (\"cyclical_encoding\", MonthCyclicalEncoder(), \"all\"),\n",
    "    (\"median_imputer\", MedianImputer(median_cols), \"all\"),\n",
    "    (\"drop_features\", FeatureDropper(always_drop=always_drop_cols), \"all\"),\n",
    "    (\"iqr_outliers\", IQRGroupOutlierRemover(group_col=\"station_number\"), \"train\"),\n",
    "    # (\"drop_features\", FeatureDropper(always_drop=[\"station_number\"]), \"all\"),\n",
    "    (\"mean_imputer\", MeanImputer(cols=[\"mean_sealevel_pressure\"]), \"all\"),\n",
    "    (\"mode_imputer\", ModeImputer(cols=[\"max_temperature_explicit\"]), \"all\"),\n",
    "    (\"knn_imputer\", KNNImputerWrapper(cols_to_knn_impute, n_neighbors=5), \"all\"),\n",
    "    (\"log_transform\", LogTransformer(cols=cols_to_log_transform), \"train\"),\n",
    "    (\"binary_flag_encode\", BinaryFlagImputerEncoder(flag_cols=binary_flags), \"all\"),\n",
    "    # (\"lag_features\", LagFeatureGenerator(col=\"snow\", lags=[1, 2, 3, 7]), \"all\"),\n",
    "    (\"target_lag\", TargetLagTransformer(\n",
    "                    target_col='snow',\n",
    "                    lag_target=True,\n",
    "                    lag_features={'mean_temp': [1], 'mean_dew_point': [1]},\n",
    "                    rolling_features={'total_precipitation': [3]},),\n",
    "                    \"all\"\n",
    "    ),\n",
    "    (\"median_imputer\", MedianImputer(cols=['mean_temp_lag1', 'mean_dew_point_lag1','total_precipitation_roll3']), \"all\"),\n",
    "]\n",
    "\n",
    "# Initialize runner\n",
    "pipeline = PipelineRunner(pipeline_steps)\n",
    "\n",
    "# Apply\n",
    "train_clean = pipeline.fit_transform(df_train)\n",
    "val_clean = pipeline.transform(df_eval, split='val')\n",
    "test_clean = pipeline.transform(df_test, split='test')\n",
    "\n",
    "\n",
    "# Separate features and targets\n",
    "X_train, y_train = separate_X_y(train_clean)\n",
    "X_val, y_val = separate_X_y(val_clean)\n",
    "X_test, y_test = separate_X_y(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_clean: No missing values.\n",
      " val_clean: No missing values.\n",
      " test_clean: No missing values.\n"
     ]
    }
   ],
   "source": [
    "from utils import check_missing\n",
    "\n",
    "# Run checks\n",
    "check_missing(train_clean, \"train_clean\")\n",
    "check_missing(val_clean, \"val_clean\")\n",
    "check_missing(test_clean, \"test_clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>mean_visibility</th>\n",
       "      <th>max_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>mean_temp_lag1</th>\n",
       "      <th>mean_dew_point_lag1</th>\n",
       "      <th>total_precipitation_roll3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>725494</td>\n",
       "      <td>49.099998</td>\n",
       "      <td>30.200001</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>725868</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>44.400002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>725868</td>\n",
       "      <td>54.500000</td>\n",
       "      <td>38.799999</td>\n",
       "      <td>1016.500000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>33.799999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>725827</td>\n",
       "      <td>48.700001</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>1011.299988</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>56.799999</td>\n",
       "      <td>37.400002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>725848</td>\n",
       "      <td>57.700001</td>\n",
       "      <td>40.599998</td>\n",
       "      <td>1024.900024</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>56.799999</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  mean_temp  mean_dew_point  mean_sealevel_pressure  \\\n",
       "2          725494  49.099998       30.200001             1016.500000   \n",
       "3          725868  20.700001       15.300000             1016.500000   \n",
       "5          725868  54.500000       38.799999             1016.500000   \n",
       "6          725827  48.700001       27.100000             1011.299988   \n",
       "7          725848  57.700001       40.599998             1024.900024   \n",
       "\n",
       "   mean_visibility  max_temperature_explicit  total_precipitation  snow  \\\n",
       "2             10.0                         1                  0.0     0   \n",
       "3             17.5                         0                  0.0     0   \n",
       "5             20.0                         0                  0.0     0   \n",
       "6             27.5                         0                  0.0     0   \n",
       "7             20.0                         1                  0.0     0   \n",
       "\n",
       "   month_sin     month_cos  mean_temp_lag1  mean_dew_point_lag1  \\\n",
       "2   0.866025 -5.000000e-01       51.599998            24.700001   \n",
       "3   0.500000  8.660254e-01       58.500000            44.400002   \n",
       "5  -0.500000 -8.660254e-01       72.500000            33.799999   \n",
       "6   0.500000 -8.660254e-01       56.799999            37.400002   \n",
       "7   1.000000  6.123234e-17       56.799999            50.000000   \n",
       "\n",
       "   total_precipitation_roll3  \n",
       "2                        0.0  \n",
       "3                        0.0  \n",
       "5                        0.0  \n",
       "6                        0.0  \n",
       "7                        0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Tabular Data with snow_tomorrow as the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 9.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:07:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.779     0.854      5428\n",
      "           1      0.309     0.683     0.426       788\n",
      "\n",
      "    accuracy                          0.767      6216\n",
      "   macro avg      0.627     0.731     0.640      6216\n",
      "weighted avg      0.864     0.767     0.799      6216\n",
      "\n",
      "Validation AUC: 0.8204\n",
      "\n",
      " Test Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.884     0.734     0.802       177\n",
      "           1      0.190     0.393     0.256        28\n",
      "\n",
      "    accuracy                          0.688       205\n",
      "   macro avg      0.537     0.564     0.529       205\n",
      "weighted avg      0.789     0.688     0.728       205\n",
      "\n",
      "Test AUC: 0.6254\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#--- Handle Class Imbalance ---\n",
    "\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# --- Train XGBoost Model ---\n",
    "model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate on Validation Set ---\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\n Validation Metrics:\")\n",
    "print(classification_report(y_val, y_val_pred, digits=3))\n",
    "print(f\"Validation AUC: {roc_auc_score(y_val, y_val_proba):.4f}\")\n",
    "\n",
    "# --- Evaluate on Test Set ---\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n Test Metrics:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(f\"Test AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "# --- Create Results DataFrame ---\n",
    "df_test_results = pd.DataFrame({\n",
    "    'date': test_clean['date'].values,\n",
    "    'true_snow': y_test,\n",
    "    'pred_snow': y_test_pred,\n",
    "    'prob_snow': y_test_proba\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of test date predictions (2005-06-22):\n",
      " Predicted snow at 58 stations\n",
      " Predicted no snow at 147 stations\n",
      "\n",
      " Ground truth:\n",
      " Actually snowed at 28 stations\n",
      " Actually no snow at 177 stations\n",
      "\n",
      " Final Forecast: In most stations, it **WILL NOT SNOW** tomorrow \n",
      " Model correctly predicted the majority outcome across stations.\n"
     ]
    }
   ],
   "source": [
    "# Count predictions\n",
    "snow_counts = df_test_results['pred_snow'].value_counts()\n",
    "num_snow = snow_counts.get(1, 0)\n",
    "num_no_snow = snow_counts.get(0, 0)\n",
    "\n",
    "# Count actual ground truth\n",
    "true_counts = df_test_results['true_snow'].value_counts()\n",
    "true_snow = true_counts.get(1, 0)\n",
    "true_no_snow = true_counts.get(0, 0)\n",
    "\n",
    "print(f\"\\n Summary of test date predictions ({df_test_results['date'].iloc[0].date()}):\")\n",
    "print(f\" Predicted snow at {num_snow} stations\")\n",
    "print(f\" Predicted no snow at {num_no_snow} stations\")\n",
    "\n",
    "print(f\"\\n Ground truth:\")\n",
    "print(f\" Actually snowed at {true_snow} stations\")\n",
    "print(f\" Actually no snow at {true_no_snow} stations\")\n",
    "\n",
    "# Final decision\n",
    "if num_snow > num_no_snow:\n",
    "    pred_majority = 1\n",
    "    print(\"\\n Final Forecast: In most stations, it **WILL SNOW** tomorrow \")\n",
    "elif num_snow < num_no_snow:\n",
    "    pred_majority = 0\n",
    "    print(\"\\n Final Forecast: In most stations, it **WILL NOT SNOW** tomorrow \")\n",
    "else:\n",
    "    pred_majority = None\n",
    "    print(\"\\n Final Forecast: Its a tie  equal predictions for snow and no snow \")\n",
    "\n",
    "# Was it correct?\n",
    "if pred_majority is not None:\n",
    "    true_majority = 1 if true_snow > true_no_snow else 0\n",
    "    if pred_majority == true_majority:\n",
    "        print(\" Model correctly predicted the majority outcome across stations.\")\n",
    "    else:\n",
    "        print(\" Model's majority prediction does not match actual majority.\")\n",
    "else:\n",
    "    print(\" Can't assess correctness due to tie.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureDropper fit complete. 34 total columns.\n",
      "Dropping 14 always dropped columns: ['year', 'day', 'wban_number', 'num_mean_temp_samples', 'num_mean_sealevel_pressure_samples', 'num_mean_wind_speed_samples', 'max_gust_wind_speed', 'max_sustained_wind_speed', 'mean_wind_speed', 'hail', 'tornado', 'thunder', 'fog', 'rain']\n",
      "Dropping 6 columns due to high missing values: ['mean_station_pressure', 'num_mean_station_pressure_samples', 'min_temperature', 'min_temperature_explicit', 'snow_depth', 'snow_depth_change']\n",
      "Dropping 4 columns due to high correlation: ['num_mean_dew_point_samples', 'num_mean_visibility_samples', 'max_gust_wind_speed', 'max_temperature']\n",
      "Dropping 10 columns from training: ['min_temperature_explicit', 'max_gust_wind_speed', 'min_temperature', 'snow_depth_change', 'num_mean_dew_point_samples', 'num_mean_station_pressure_samples', 'num_mean_visibility_samples', 'max_temperature', 'snow_depth', 'mean_station_pressure']\n"
     ]
    }
   ],
   "source": [
    "from pipeline.transformers.median_imputer import MedianImputer\n",
    "from pipeline.transformers.cyclical_encoder import MonthCyclicalEncoder\n",
    "from pipeline.transformers.outlier import IQRGroupOutlierRemover\n",
    "from pipeline.pipeline_runner import PipelineRunner\n",
    "from pipeline.transformers.feature_dropper import FeatureDropper\n",
    "from pipeline.transformers.binary_flag_imputer import BinaryFlagImputerEncoder\n",
    "from pipeline.transformers.log_transform import LogTransformer\n",
    "from pipeline.transformers.mean_imputer import MeanImputer\n",
    "from pipeline.transformers.knn_imputer import KNNImputerWrapper\n",
    "from pipeline.transformers.mode_imputer import ModeImputer\n",
    "from pipeline.transformers.lag_feature_generator import LagFeatureGenerator\n",
    "from pipeline.transformers.target_lag import TargetLagTransformer\n",
    "\n",
    "\n",
    "def separate_X_y(df, target_col='snow_tomorrow', drop_cols=['date']):\n",
    "    # Check that target exists\n",
    "    assert target_col in df.columns, f\"Target column '{target_col}' not found in DataFrame.\"\n",
    "    \n",
    "    # Drop target and any specified columns from features\n",
    "    X = df.drop(columns=[target_col] + drop_cols, errors='ignore')\n",
    "    y = df[target_col].astype(int)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Define columns\n",
    "median_cols = ['mean_temp', 'mean_dew_point', 'mean_sealevel_pressure', 'max_temperature']\n",
    "numeric_cols = df_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Columns to always drop from all splits\n",
    "always_drop_cols = [\n",
    "    'year', \n",
    "    # 'month', \n",
    "    'day', 'wban_number',\n",
    "    'num_mean_temp_samples', 'num_mean_sealevel_pressure_samples',\n",
    "    'num_mean_wind_speed_samples', 'max_gust_wind_speed',\n",
    "    'max_sustained_wind_speed', 'mean_wind_speed', \n",
    "    'hail', 'tornado', 'thunder', 'fog', 'rain',\n",
    "\n",
    "    # 'month_sin'\n",
    "]\n",
    "\n",
    "binary_flags = ['fog', 'rain', 'snow', 'hail', 'thunder', 'tornado','max_temperature_explicit']\n",
    "\n",
    "\n",
    "cols_to_log_transform = [\n",
    "    # 'mean_wind_speed',\n",
    "    # 'max_sustained_wind_speed',\n",
    "    'total_precipitation'\n",
    "]\n",
    "\n",
    "cols_to_knn_impute = ['total_precipitation', 'mean_visibility']\n",
    "\n",
    "# Build pipeline\n",
    "pipeline_steps = [\n",
    "    (\"cyclical_encoding\", MonthCyclicalEncoder(), \"all\"),\n",
    "    (\"median_imputer\", MedianImputer(median_cols), \"all\"),\n",
    "    (\"drop_features\", FeatureDropper(always_drop=always_drop_cols), \"all\"),\n",
    "    (\"iqr_outliers\", IQRGroupOutlierRemover(group_col=\"station_number\"), \"train\"),\n",
    "    # (\"drop_features\", FeatureDropper(always_drop=[\"station_number\"]), \"all\"),\n",
    "    (\"mean_imputer\", MeanImputer(cols=[\"mean_sealevel_pressure\"]), \"all\"),\n",
    "    (\"mode_imputer\", ModeImputer(cols=[\"max_temperature_explicit\"]), \"all\"),\n",
    "    (\"knn_imputer\", KNNImputerWrapper(cols_to_knn_impute, n_neighbors=5), \"all\"),\n",
    "    (\"log_transform\", LogTransformer(cols=cols_to_log_transform), \"train\"),\n",
    "    (\"binary_flag_encode\", BinaryFlagImputerEncoder(flag_cols=binary_flags), \"all\"),\n",
    "    # (\"lag_features\", LagFeatureGenerator(col=\"snow\", lags=[1, 2, 3, 7]), \"all\"),\n",
    "    (\"target_lag\", TargetLagTransformer(\n",
    "                    target_col='snow',\n",
    "                    lag_target=True,\n",
    "                    lag_features={},\n",
    "                    rolling_features={'total_precipitation': [3]},),\n",
    "                    \"all\"\n",
    "    ),\n",
    "    (\"median_imputer\", MedianImputer(cols=['total_precipitation_roll3']), \"all\"),\n",
    "]\n",
    "\n",
    "# Initialize runner\n",
    "pipeline = PipelineRunner(pipeline_steps)\n",
    "\n",
    "# Apply\n",
    "train_clean = pipeline.fit_transform(df_train)\n",
    "val_clean = pipeline.transform(df_eval, split='val')\n",
    "test_clean = pipeline.transform(df_test, split='test')\n",
    "\n",
    "\n",
    "# Separate features and targets\n",
    "X_train, y_train = separate_X_y(train_clean)\n",
    "X_val, y_val = separate_X_y(val_clean)\n",
    "X_test, y_test = separate_X_y(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6216, 13), (205, 13), (293512, 13))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_clean.shape, test_clean.shape, train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generated 292028 sequences from 212 stations.\n",
      " Skipped 0 stations due to insufficient length (< 8)\n",
      " Generated 4743 sequences from 209 stations.\n",
      " Skipped 2 stations due to insufficient length (< 8)\n",
      " Generated 0 sequences from 0 stations.\n",
      " Skipped 205 stations due to insufficient length (< 8)\n",
      "torch.Size([292028, 7, 11])\n",
      "torch.Size([292028])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_sequences_from_df(df, input_cols, target_col, seq_len, group_col=\"station_number\", time_col=\"date\"):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    skipped_groups = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    df[time_col] = pd.to_datetime(df[time_col])  # just in case\n",
    "    for station_id, group in df.groupby(group_col):\n",
    "        group = group.sort_values(time_col)\n",
    "        if len(group) < seq_len + 1:\n",
    "            skipped_groups += 1\n",
    "            continue\n",
    "\n",
    "        features = group[input_cols].values\n",
    "        target = group[target_col].values\n",
    "\n",
    "        for i in range(len(group) - seq_len):\n",
    "            X_seq = features[i:i + seq_len]\n",
    "            y_seq = target[i + seq_len]\n",
    "            sequences.append(X_seq)\n",
    "            targets.append(y_seq)\n",
    "            total_sequences += 1\n",
    "\n",
    "    print(f\" Generated {total_sequences} sequences from {len(df[group_col].unique()) - skipped_groups} stations.\")\n",
    "    print(f\" Skipped {skipped_groups} stations due to insufficient length (< {seq_len + 1})\")\n",
    "    return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seq_len_input = 7\n",
    "\n",
    "input_cols = [col for col in train_clean.columns if col not in ['snow_tomorrow', 'date']]  # safe filtering\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_from_df(train_clean, input_cols, 'snow_tomorrow', seq_len=seq_len_input)\n",
    "X_val_seq, y_val_seq     = create_sequences_from_df(val_clean, input_cols, 'snow_tomorrow', seq_len=seq_len_input)\n",
    "X_test_seq, y_test_seq   = create_sequences_from_df(test_clean, input_cols, 'snow_tomorrow', seq_len=seq_len_input)\n",
    "\n",
    "\n",
    "print(X_train_seq.shape)  # (num_samples, seq_len, num_features)\n",
    "print(y_train_seq.shape)  # (num_samples,)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_seq, y_train_seq), batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_seq, y_val_seq), batch_size=64)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_seq, y_test_seq), batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({0: 263380, 1: 28648})\n",
      "Class weights: tensor([ 1.1088, 10.1937])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|| 4563/4563 [00:48<00:00, 94.81it/s, loss=0.679] \n",
      "Epoch 1/10 [Val]: 100%|| 75/75 [00:00<00:00, 443.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.6937 - Val Acc: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]:  13%|        | 595/4563 [00:06<00:46, 86.21it/s, loss=0.68] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     94\u001b[39m         val_acc = correct / total\n\u001b[32m     95\u001b[39m         tqdm.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m    107\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, device, epochs)\u001b[39m\n\u001b[32m     68\u001b[39m X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\u001b[32m     70\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m     73\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mLSTMClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# x: (batch_size, seq_len, input_size)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     output, (hn, cn) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     last_hidden = hn[-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# shape: (batch_size, hidden_size)\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(last_hidden)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\miniconda\\envs\\talent_sort\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=128,        #  increased capacity\n",
    "        num_layers=3,           #  deeper LSTM\n",
    "        dropout=0.3,            # regularize if deeper\n",
    "        num_classes=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        last_hidden = hn[-1]  # shape: (batch_size, hidden_size)\n",
    "        return self.fc(last_hidden)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMClassifier(input_size=X_train_seq.shape[2], hidden_size=64).to(device)\n",
    "\n",
    "# y_train_seq is your label tensor (1D)\n",
    "counts = Counter(y_train_seq.tolist())\n",
    "print(\"Class counts:\", counts)\n",
    "\n",
    "# Create inverse-frequency weights (higher weight for minority class)\n",
    "num_samples = sum(counts.values())\n",
    "weights = [num_samples / counts[i] for i in range(len(counts))]\n",
    "weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Class weights:\", weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=True)\n",
    "        for X_batch, y_batch in train_iter:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            train_iter.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        val_iter = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=True)\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_iter:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        tqdm.write(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talent_sort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
